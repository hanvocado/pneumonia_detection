{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNtCyXFhAIOHWD0IDbd1g+N",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hanvocado/pneumonia_detection/blob/linh/src/preprocess/split_dataset_new.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ybuMBM_UO4FL"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "import shutil\n",
        "import random\n",
        "import numpy as np\n",
        "from glob import glob\n",
        "from tqdm import tqdm\n",
        "import cv2\n",
        "\n",
        "# THIẾT LẬP MÔI TRƯỜNG & ĐƯỜNG DẪN\n",
        "current_directory = os.getcwd()\n",
        "\n",
        "while not current_directory.endswith('pneumonia_detection'):\n",
        "    parent = os.path.dirname(current_directory)\n",
        "    if parent == current_directory:\n",
        "        print(\"⚠️ Không tìm thấy thư mục 'pneumonia_detection'. Dùng thư mục hiện tại.\")\n",
        "        break\n",
        "    current_directory = parent\n",
        "\n",
        "root_directory = current_directory\n",
        "os.chdir(root_directory)\n",
        "sys.path.insert(0, root_directory)\n",
        "\n",
        "INPUT_DIR = os.path.join(root_directory, 'data_processed')\n",
        "OUTPUT_DIR = os.path.join(root_directory, 'data_processed_new')\n",
        "\n",
        "TRAIN_RATIO = 0.70\n",
        "VAL_RATIO = 0.15\n",
        "TEST_RATIO = 0.15\n",
        "\n",
        "# IN BẢNG THỐNG KÊ\n",
        "\n",
        "def print_summary_table(title):\n",
        "\n",
        "    print(f\"\\n{'='*45}\")\n",
        "    print(f\"{title:^45}\")\n",
        "    print(f\"{'='*45}\")\n",
        "\n",
        "    header = f\"{'Split':<10} {'NORMAL':<10} {'PNEUMONIA':<10} {'Total':<10}\"\n",
        "    print(header)\n",
        "    print(\"-\" * 45)\n",
        "\n",
        "    splits = ['train', 'val', 'test']\n",
        "    labels = ['NORMAL', 'PNEUMONIA']\n",
        "\n",
        "    for split in splits:\n",
        "        counts = []\n",
        "        row_total = 0\n",
        "        for label in labels:\n",
        "            path = os.path.join(OUTPUT_DIR, split, label)\n",
        "            files = glob(os.path.join(path, '*'))\n",
        "            count = len(files)\n",
        "            counts.append(count)\n",
        "            row_total += count\n",
        "\n",
        "        split_name = split.capitalize()\n",
        "        row_str = f\"{split_name:<10} {counts[0]:<10,} {counts[1]:<10,} {row_total:<10,}\"\n",
        "        print(row_str)\n",
        "    print(\"-\" * 45 + \"\\n\")\n",
        "\n",
        "# CHIA DỮ LIỆU\n",
        "\n",
        "def stratified_split():\n",
        "    if not os.path.exists(INPUT_DIR):\n",
        "        print(f\"Lỗi: Không tìm thấy folder nguồn '{INPUT_DIR}'\")\n",
        "        return False\n",
        "\n",
        "    if os.path.exists(OUTPUT_DIR):\n",
        "        shutil.rmtree(OUTPUT_DIR)\n",
        "\n",
        "    for split in ['train', 'val', 'test']:\n",
        "        for label in ['NORMAL', 'PNEUMONIA']:\n",
        "            os.makedirs(os.path.join(OUTPUT_DIR, split, label), exist_ok=True)\n",
        "\n",
        "    print(\"Đang thực hiện chia dữ liệu...\", end=\"\\r\")\n",
        "\n",
        "    for label in ['NORMAL', 'PNEUMONIA']:\n",
        "        # Gom ảnh\n",
        "        files = glob(os.path.join(INPUT_DIR, '*', label, '*.jpeg')) + \\\n",
        "                glob(os.path.join(INPUT_DIR, '*', label, '*.jpg')) + \\\n",
        "                glob(os.path.join(INPUT_DIR, label, '*.jpeg')) + \\\n",
        "                glob(os.path.join(INPUT_DIR, label, '*.jpg'))\n",
        "\n",
        "        files = list(set(files))\n",
        "        total_files = len(files)\n",
        "\n",
        "        if total_files == 0: continue\n",
        "\n",
        "        random.shuffle(files)\n",
        "        train_end = int(total_files * TRAIN_RATIO)\n",
        "        val_end = train_end + int(total_files * VAL_RATIO)\n",
        "\n",
        "        train_files = files[:train_end]\n",
        "        val_files = files[train_end:val_end]\n",
        "        test_files = files[val_end:]\n",
        "\n",
        "        for f in train_files: shutil.copy2(f, os.path.join(OUTPUT_DIR, 'train', label))\n",
        "        for f in val_files:   shutil.copy2(f, os.path.join(OUTPUT_DIR, 'val', label))\n",
        "        for f in test_files:  shutil.copy2(f, os.path.join(OUTPUT_DIR, 'test', label))\n",
        "\n",
        "    return True\n",
        "\n",
        "#TĂNG CƯỜNG DỮ LIỆU\n",
        "\n",
        "def augment_image_logic(image_path, save_path):\n",
        "    try:\n",
        "        img = cv2.imread(image_path, 0)\n",
        "        if img is None: return\n",
        "\n",
        "        choice = random.randint(0, 1)\n",
        "        if choice == 0:\n",
        "            aug_img = cv2.flip(img, 1) # Flip ngang\n",
        "        else:\n",
        "            rows, cols = img.shape\n",
        "            tx = random.randint(-10, 10) #Translation\n",
        "            ty = random.randint(-10, 10)\n",
        "            M = np.float32([[1, 0, tx], [0, 1, ty]])\n",
        "            aug_img = cv2.warpAffine(img, M, (cols, rows))\n",
        "\n",
        "        cv2.imwrite(save_path, aug_img)\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "def balance_train_data():\n",
        "    train_dir = os.path.join(OUTPUT_DIR, 'train')\n",
        "\n",
        "    normal_path = os.path.join(train_dir, 'NORMAL')\n",
        "    pneumonia_path = os.path.join(train_dir, 'PNEUMONIA')\n",
        "\n",
        "    normal_files = glob(os.path.join(normal_path, '*'))\n",
        "    pneumonia_files = glob(os.path.join(pneumonia_path, '*'))\n",
        "\n",
        "    n_count = len(normal_files)\n",
        "    p_count = len(pneumonia_files)\n",
        "    target_count = max(n_count, p_count)\n",
        "\n",
        "    if n_count < target_count:\n",
        "        needed = target_count - n_count\n",
        "        print(f\"Đang tăng cường lớp NORMAL (Sinh thêm {needed} ảnh)...\")\n",
        "\n",
        "        for i in tqdm(range(needed), desc=\"Augmenting\", unit=\"img\"):\n",
        "            src_img = random.choice(normal_files)\n",
        "            new_filename = f\"aug_{i}_{os.path.basename(src_img)}\"\n",
        "            dst_path = os.path.join(normal_path, new_filename)\n",
        "            augment_image_logic(src_img, dst_path)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    success = stratified_split()\n",
        "    if success:\n",
        "        print_summary_table(\"KẾT QUẢ SAU KHI CHIA LẠI DỮ LIỆU\")\n",
        "        balance_train_data()\n",
        "        print_summary_table(\"KẾT QUẢ SAU KHI TĂNG CƯỜNG\")\n",
        "\n",
        "        print(f\"Hoàn tất!\")\n",
        "    else:\n",
        "        print(\"Quy trình thất bại.\")"
      ]
    }
  ]
}